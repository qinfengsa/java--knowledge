## ZooKeeper 

ZooKeeper 是一个开源的分布式协调服务，ZooKeeper 的设计目标是将那些复杂且容易出错的分布式一致性服务封装起来，构成一个高效可靠的原语集，并以一系列简单易用的接口提供给用户使用。ZooKeeper 是一个典型的分布式数据一致性解决方案，分布式应用程序可以基于 ZooKeeper 实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能。

ZooKeeper 将数据保存在内存中，这也就保证了 高吞吐量和低延迟（但是内存限制了能够存储的容量不太大，此限制也是保持ZNode中存储的数据量较小的进一步原因）。

ZooKeeper 底层其实只提供了两个功能：

* 管理（存储、读取）用户程序提交的数据；
* 为用户程序提供数据节点监听服务

## ZooKeeper 重要概念

### 集群角色

ZooKeeper 本身就是一个分布式程序，为了保证高可用，需要以以集群形态来部署 ZooKeeper；ZooKeeper 集群是一个基于主从复制的高可用集群；有以下3种角色

| 角色     | 工作描述                                                     |
| -------- | ------------------------------------------------------------ |
| Leader   | 1. 事务请求的唯一调度和处理者，保证集群事务处理的顺序性;<br/>2. 集群内部各服务器的调度者; |
| Follower | 1. 处理客户端非事务请求，转发事务请求给 Leader服务器；<br/>2. 参与事务请求 Proposal的投票；<br/>3. 参与 Leader选举投票. |
| Observer | 1. Observer和Follower类似，唯一的区别在于Observer不参与投票和选举；<br/>2. 增加Observer可以在不影响写性能的情况下提高读性能 |



### 会话(Session)

- session是客户端与ZooKeeper 服务端之间建立的长链接；
- ZooKeeper 在一个会话中进行心跳检测来感知客户端链接的存活；
- ZooKeeper 客户端在一个会话中接收来自服务端的watch事件通知；
- ZooKeeper 可以给会话设置超时时间；

### 数据节点(ZNode)

- ZNode是ZooKeeper 树形结构中的数据节点，用于存储数据；
- ZNode分为持久节点和临时节点两种类型：
  - **持久节点(PERSISTENT)**：一旦创建，除非主动调用删除操作，否则一直存储在ZooKeeper 上；
  - **持久有序节点(PERSISTENT_SEQUENTIAL)**：每个节点都会为它的一级子节点维护一个顺序；
  - **临时节点(EPHEMERAL)**：临时节点的生命周期和客户端的会话绑定在一起，当客户端会话失效该节点自动清理；
  - **临时有序节点(EPHEMERAL_SEQUENTIAL)**：在临时节点的基础上多了一个顺序性
  - **CONTAINER**：当子节点都被删除后，Container 也随即删除
  - **PERSISTENT_WITH_TTL和PERSISTENT_SEQUENTIAL_WITH_TTL**：带TTL（time-to-live，存活时间）的永久节点，客户端断开连接后，节点在TTL时间之内没有得到更新并且没有孩子节点，就会被自动删除。

### 版本

- Version：代表当前ZNode的版本；
- CVersion：代表当前ZNode的子节点的版本，子节点发生变化时会增加该版本号的值；
- AVersion：代表当前ZNode的ACL(访问控制)的版本，修改节点的访问控制权限时会增加该版本号的值；



### Watcher

- watcher监听在ZNode节点上；
- 当节点的数据更新或子节点的状态发生变化都会使客户端的watcher得到通知；





### ACL(访问控制)

有以下几种访问控制权限：

- CREATE：创建子节点的权限；
- READ：获取节点数据和子节点列表的权限；
- WRITE：更新节点数据的权限；
- DELETE: 删除子节点的权限；
- ADMIN：设置节点ACL的权限；

## ZooKeeper 特点

- **顺序一致性：** 从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到 ZooKeeper 中去。
- **原子性：** 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。
- **单一系统映像 ：** 无论客户端连到哪一个 ZooKeeper 服务器上，其看到的服务端数据模型都是一致的。
- **可靠性：** 一旦一次更改请求被应用，更改的结果就会被持久化，直到被下一次更改覆盖。

## 一致性协议

### 2PC

**2PC**：是Two- Phase commit的缩写，即二阶段提交，是计算机网络尤其是在数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务处理过程中能够保持原子性和一致性而设计的一种算法；

顾名思义，二阶段提交协议是将事务的提交过程分成了两个阶段来进行处理，其执行流程如下

**阶段一：提交事务请求**

类似投票阶段，而且是一票否决

1. **事务询问**

   协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应 

2. **执行事务**

   各参与者节点执行事务操作，并将Undo和Redo信息记入事务日志中

3. **各参与者向协调者反馈事务响应**

   如果参与者成功执行了事务，反馈Yes响应，表示事务可以执行；

   如果参与者没有成功执行事务，反馈No响应，表示事务不可以执行。

**阶段二：执行事务提交**

在阶段二中，协调者会根据各参与者的反馈情况来决定最终是否可以进行事务提交操作，包含以下两种可能
**执行事务提交**：所有的反馈都是Yes响应

1. **发送提交请求**

   协调者向所有参与者节点发出 Commit请求

2. **事务提交**

   参与者接收到 Commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源

3. **反馈事务提交结果**

   参与者在完成事务提交之后,向协调者发送Ack消息

4. **完成事务**

   协调者接收到所有参与者反馈的Ack消息后，完成事务

**中断事务：**任何一个参与者反馈了No响应，或者等待超时

1. **发送回滚请求**

   协调者向所有参与者节点发出 Rollback请求

2. **事务回滚**

   参与者接收到 Rollback请求后，会利用其在阶段一中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源

3. **反馈事务回滚结果**

   参与者在完成事务回滚之后，向协调者发送Ack消息

4. **中断事务**

   协调者接收到所有参与者反馈的Ack消息后，完成事务中断.

二阶段提交将一个事务的处理过程分为了投票和执行两个阶段，其核心是对每个事务都采用先尝试后提交的处理方式，因此也可以将二阶段提交看作一个强一致性的算法；

**优点：**原理简单,实现方便.
**缺点：**同步阻塞、单点问题、数据不一致、容错性

* 同步阻塞：在二阶段提交的执行过程中，所有参与的事务都处于阻塞状态，会导致无法进行其他操作
* 单点问题：协调者在2PC过程中作用非常重要，职责过重，如果协调者出现问题，会导致整个事务操作不可用
* 数据不一致：如果阶段二提交过程中，Commit请求中发生网络异常等问题，会导致只有部分参与者进行事务提交，使得数据和其它未提交的参与者不一致
* 容错性：由于投票阶段使用一票否决制，导致在复杂的网络环境下容错性非常差，只要有一台参与者发生故障或网络问题，整个事务一直失败

### 3PC

**3PC**：是 Three-Phase Commit的缩写，即三阶段提交，是2PC的改进版，其将二阶段提交协议的"提交事务请求"过程一分为二，形成了由 Can Commit、 PreCommit和 do Commit三个阶段组成的事务处理协议；

**阶段一: Can Commit**

1. **事务询问**

   协调者向所有的参与者发送一个包含事务内容的can Commit请求，询问是否可以执行事务提交操作，并等待各参与者的响应. 

2. **各参与者向协调者反馈响应.**

   参与者在接收到来自协调者的 can Commit请求后，如果其自身认为可以顺利执行事务，反馈Yes响应，并进入预备状态，

   否则反馈No响应

**阶段二: Pre Commit**

在阶段二中，协调者会根据参与者的反馈情况来决定是否可以进行事务的 PreCommit操作，包含两种可能

**执行事务预提交**：所有的反馈都是Yes响应 

1. **发送预提交请求**

   协调者向所有参与者节点发出 pre Commit的请求，并进入 Prepared阶段.

2. **事务预提交**

   参与者接收到 pre Commit请求后，会执行事务操作，并将Undo和Redo信息记录到事务日志中 

3. **各参与者向协调者反馈事务执行的响应**

   如果参与者成功执行了事务操作，那么就会反馈给协调者Ack响应，同时等待最终的指令:提交( commit)或中止( abort)

**中断事务：**任何一个参与者反馈了No响应，或者等待超时

1. **发送中断请求**

   协调者向所有参与者节点发出 abort请求.

2. **中断事务**

   无论是收到来自协调者的abort请求，或者是在等待协调者请求过程中出现超时，参与者都会中断事务.

**阶段三: do Commit**

真正的事务提交，会存在以下两种可能的情况

**执行提交**

1. **发送提交请求**

   进入这一阶段，假设协调者处于正常工作状态，并且它接收到了来自所有参与者的Ack响应，那么它将从"预提交"状态转换到"提交"状态，并向所有的参与者发送 do Commit请求.

2. **事务提交**

   参与者接收到 do Commit请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源

3. **反馈事务提交结果**

   参与者在完成事务提交之后，向协调者发送Ack消息

4. **完成事务**

   协调者接收到所有参与者反馈的Ack消息后，完成事务

**中断事务：**任何一个参与者反馈了No响应，或者等待超时

1. **发送中断请求**

   协调者向所有参与者节点发出 abort请求

2. **事务回滚**

   参与者接收到 abort请求后，会利用其在阶段二中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源

3. **反馈事务回滚结果**

   参与者在完成事务回滚之后，向协调者发送Ack消息

4. **中断事务**

   协调者接收到所有参与者反馈的Ack消息后，完成事务中断.

**优点：**相较于二阶段提交协议，三阶段提交协议最大的优点就是降低了参与者的阻塞范围，并且能够在出现单点故障后继续达成

**缺点：**三阶段提交协议在去除阻塞的同时也引入了新的问题，那就是在参与者接收到 pre Commit消息后，如果网络出现分区，此时协调者所在的节点和参与者无法进行正常的网络通信，在这种情况下，该参与者依然会进行事务的提交，这必然出现数据的不一致性.

### PAXOS协议

Paxos三种角色：Proposer, Acceptor, Learner 

* **Proposer：**只要 Proposer发的提案被半数以上 Acceptor接受，Proposer就认为该提案里的value被选定
* **Acceptor：**只要 Acceptor接受了某个提案，Acceptor I就认为该提案里的 value被选定了
* **Learner :   **Acceptor告诉 Learner哪个 value被选定，Learner就认为那个value被选定

Paxos算法分为两个阶段：
**阶段一(准 leader 确定)**

1. Proposer选择一个提案编号N，然后向半数以上的 Acceptor发送编号为N的 Prepare请求
2. 如果一个 Acceptor收到一个编号为N的 Prepare请求，且N大于该 Acceptor已经响应过的所有 Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案(如果有的话)作为响应反馈给 Proposer，同时该 Acceptor承诺不再接受任何编号小于N的提案

**阶段二( Leader确认)**

1. 如果 Proposer收到半数以上 Acceptor对其发出的编号为N的 Prepare请求的响应，那么它就会发送一个针对[N，V]提案的 Accept请求给半数以上的 Acceptor（注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由 Proposer自己决定）
2. 如果 Acceptor收到一个针对编号为N的提案的 Accept请求，只要该 Acceptor没有对编号大于N的 Prepare请求做出过响应，它就接受该提案.

### ZAB 协议 

> ZAB协议的核心是定义了对于那些会改变ZooKeeper服务器数据状态的事务请求的处理方式，即：
>
> 所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为 Leader服务器，而余下的其他服务器则成为 Follower服务器。Leader服务器负责将一个客户端事务请求转换成一个事务 Proposal(提议)，并将该 Proposal分发给集群中所有的Follower服务器。之后 Leader服务器需要等待所有 Follower服务器的反馈，一旦超过半数的 Follower服务器进行了正确的反馈后，那么 Leader就会再次向所有的 Follower服务器分发 Commit消息，要求其将前一个 Proposal进行提交。

ZAB协议包括两种基本的模式，分别是 **崩溃恢复和消息广播**。

**消息广播：**广播的过程实际上是一个简化的2PC过程：

1. Leader 接收到消息请求后，将消息赋予一个全局唯一的 64 位自增 id(事务ID)，叫做：zxid，通过 zxid 的大小比较即可实现因果有序这一特性。
2. Leader 通过FIFO先进先出队列（通过 TCP 协议来实现，以此实现了全局有序这一特性）将带有 zxid 的消息作为一个提案（proposal）分发给所有 follower。
3. 当 follower 接收到 proposal，先将 proposal 写到硬盘，写硬盘成功后再向 leader 回一个 ACK。
4. 当 leader 接收到合法数量（超过半数节点）的 ACKs 后，leader 就向所有 follower 发送 COMMIT 命令，同事会在本地执行该消息。
5. 当 follower 收到消息的 COMMIT 命令时，就会执行该消息

在这种简化了的二阶段提交模型下，是无法处理 Leader服务器崩溃退出而带来的数据不一致问题的，因此在ZAB协议中添加了另一个模式，即釆用崩溃恢复模式来解决这个问题。另外，整个消息广播协议是基于具有FIFO特性的TCP协议来进行网络通信的，因此能够很容易地保证消息广播过程中消息接收与发送的顺序性。

**崩溃恢复：** Zab 协议的广播部分不能处理 leader 挂掉的情况，Zab 协议引入了恢复模式来处理这一问题。为了使 leader 挂了后系统能正常工作，需要解决以下两个问题：

**已经被处理的消息不能丢**

为了实现已经被处理的消息不能丢这个目的，Zab 的恢复模式使用了以下的策略：

1. 选举拥有 proposal 最大值（即 zxid 最大） 的节点作为新的 leader：由于所有提案被 COMMIT 之前必须有合法数量的 follower ACK，即必须有合法数量的服务器的事务日志上有该提案的 proposal，因此，只要有合法数量的节点正常工作，就必然有一个节点保存了所有被 COMMIT 消息的 proposal 状态。
2. 新的 leader 将自己事务日志中 proposal 但未 COMMIT 的消息处理。
3. 新的 leader 与 follower 建立先进先出的队列， 先将自身有而 follower 没有的 proposal 发送给 follower，再将这些 proposal 的 COMMIT 命令发送给 follower，以保证所有的 follower 都保存了所有的 proposal、所有的 follower 都处理了所有的消息。
   通过以上策略，能保证已经被处理的消息不会丢

**被丢弃的消息不能再次出现**

Zab 通过巧妙的设计 zxid 来实现这一目的。一个 zxid 是64位，高 32 是朝代（epoch）编号，每经过一次 leader 选举产生一个新的 leader，新 leader 会将 epoch 号 +1。低 32 位是消息计数器，每接收到一条消息这个值 +1，新 leader 选举后这个值重置为 0。这样设计的好处是旧的 leader 挂了后重启，它不会被选举为 leader，因为此时它的 zxid 肯定小于当前的新 leader。当旧的 leader 作为 follower 接入新的 leader 后，新的 leader 会让它将所有的拥有旧的 epoch 号的未被 COMMIT 的 proposal 清除。

## ZooKeeper 数据模型

在ZooKeeper中，节点也称为ZNode。由于对于程序员来说，对ZooKeeper 的操作主要是对ZNode的操作;

ZooKeeper采用了类似文件系统的的数据模型，其节点构成了一个具有层级关系的树状结构

<img src="img/zookeeper-node.png" alt="img" style="zoom:80%;" />

ZNode是ZooKeeper 树形结构中的数据节点，用于存储数据；

ZNode分为持久节点和临时节点两种类型：

- **持久节点(PERSISTENT)**：一旦创建，除非主动调用删除操作，否则一直存储在ZooKeeper 上；
- **持久有序节点(PERSISTENT_SEQUENTIAL)**：每个节点都会为它的一级子节点维护一个顺序；
- **临时节点(EPHEMERAL)**：临时节点的生命周期和客户端的会话绑定在一起，当客户端会话失效该节点自动清理；
- **临时有序节点(EPHEMERAL_SEQUENTIAL)**：在临时节点的基础上多了一个顺序性
- **CONTAINER**：当子节点都被删除后，Container 也随即删除
- **PERSISTENT_WITH_TTL和PERSISTENT_SEQUENTIAL_WITH_TTL**：带TTL（time-to-live，存活时间）的永久节点，客户端断开连接后，节点在TTL时间之内没有得到更新并且没有孩子节点，就会被自动删除。

**事务ID**：在ZooKeeper中，事务是指能够改变 ZooKeeper 服务器状态的操作，我们也称之为事务操作或更新操作，一般包括数据节点创建与删除、数据节点内容更新和客户端会话创建与失效等操作。

**对于每一个事务请求，ZooKeeper 都会为其分配一个全局唯一的事务ID,用 ZXID 来表示**，通常是一个64位的数字。每一个ZXID对应一次更新操作，**从这些 ZXID 中可以间接地识别出ZooKeeper处理这些更新操作请求的全局顺序**。

实现中zxid 是一个64 位的数字，它高32 位是epoch（ZAB 协议通过epoch 编号来区分Leader 周期变化的策略）用来标识leader 关系是否改变，每次一个leader 被选出来，它都会有一个新的epoch=（原来的epoch+1），标识当前属于那个leader 的统治时期。低32 位用于递增计数。

### ZNode状态属性

|    状态属性    | 说明                                                         |
| :------------: | :----------------------------------------------------------- |
|     czxid      | Created ZXID，表示该数据节点被创建时的事务ID                 |
|     mzxid      | Modified ZXID，表示该节点最后一次被更新时的事务ID            |
|     ctime      | Created Time，表示节点被创建的时间                           |
|     mtime      | Modified Time，表示该节点最后一次被更新的时间                |
|    version     | 数据节点的版本号                                             |
|    cversion    | 子节点的版本号                                               |
|    aversion    | 节点的ACL版本号                                              |
| ephemeralOwner | 创建该临时节点的会话的 session；如果该节点是持久节点，那么这个属性值为0 |
|   dataLength   | 数据内容的长度                                               |
|  numChildren   | 当前节点的子节点个数                                         |
|     pzxid      | 表示该节点的子节点列表最后一次被修改时的事务ID；<br/>注意：只有子节点列表变更了才会变更 pzxid，子节点内容变更不会影响 pzxid |

### 版本--保证分布式数据原子性操作

ZooKeeper中为数据节点引入了版本的概念，每个数据节点都具有三种类型的版本信息，对数据节点的任何更新操作都会引起版本号的变化 

| 版本类型 | 说明                                                         |
| -------- | ------------------------------------------------------------ |
| version  | 当前数据节点数据内容的版本号；每次对节点进行更新操作，version的值都会增加1 |
| cversion | 当前数据节点子节点的版本号                                   |
| aversion | 当前数据节点ACL变更版本号                                    |



## ZooKeeper 原理

### **ZooKeeper 一致性**

简单来说：顺序一致性是针对单个操作，单个数据对象。属于CAP 中C这个范畴。一个数据被更新后，能够立马被后续的读操作读到。

client 会记录自己已经读取到的最大的zxid，如果client 重连到server 发现 client 的zxid 更大。连接会失败；client 只要连接过一次zookeeper，就不会有历史的倒退

### **ZooKeeper 分布式锁**

**利用节点的唯一性来实现分布式锁**

多个进程往ZooKeeper 的指定节点下创建一个相同名称的节点，只有一个能成功，其余创建失败；创建失败的节点全部通过ZooKeeper 的watcher 机制来监听ZooKeeper 这个子节点的变化，一旦监听到子节点的删除事件，则再次触发所有进程去写锁；

这种实现方式很简单，但是会产生“惊群效应”，简单来说就是如果存在许多的客户端在等待获取锁，当成功获取到锁的进程释放该节点后，所有处于等待状态的客户端都会被唤醒，这个时候ZooKeeper 在短时间内发送大量子节点变更事件给所有待获取锁的客户端，然后实际情况是只会有一个客户端获得锁。如果在集群规模比较大的情况下，会对ZooKeeper 服务器的性能产生比较的影响。
 

**利用临时有序节点来实现分布式锁**

- 多个进程往ZooKeeper 的指定节点下创建一个临时顺序节点
- 如果自己不是第一个节点，就对自己上一个节点加监听器
- 只要上一个节点释放锁，自己就可以获得锁，相当于是一个排队机制。

## Leader 选举

**myid：**每个ZooKeeper服务器，都需要在数据文件夹下创建一个名为myid的文件，该文件包含整个ZooKeeper集群唯一的ID（整数），编号越大在选举算法中的权重越大

**zxid：**事务ID，值越大说明数据越新，在选举算法中的权重也越大

**逻辑时钟（epoch –logicalclock）：**或者叫投票的次数，同一轮投票过程中的逻辑时钟值是相同的。每投完一次票这个数据就会增加，然后与接收到的其它服务器返回的投票信息中的数值相比，根据不同的值做出不同的判断。

**服务器状态：**

* LOOKING，竞选状态。
* FOLLOWING，随从状态，同步leader 状态，参与投票。
* OBSERVING，观察状态,同步leader 状态，不参与投票。
* LEADING，领导者状态。



### 服务器启动期间的Leader 选举

每个节点启动的时候状态都是LOOKING，处于观望状态，接下来就开始进行选主流程

若进行Leader 选举，则至少需要两台机器，这里选取3 台机器组成的服务器集群为例。在集群初始化阶段，当有一台服务器Server1 启动时，其单独无法进行和完成Leader 选举，当第二台服务器Server2 启动时，此时两台机器可以相互通信，每台机器都试图找到Leader，于是进入Leader选举过程。选举过程如下

1. **每个Server 发出一个投票：**由于是初始情况，Server1 和Server2 都会将自己作为Leader 服务器来进行投票，每次投票会包含所推举的服务器的myid 和ZXID、epoch，使用(myid, ZXID,epoch)来表示，此时Server1 的投票为(1, 0)，Server2 的投票为(2, 0)，然后各自将这个投票发给集群中其他机器。

2. **接受来自各个服务器的投票：**集群的每个服务器收到投票后，首先判断该投票的有效性，如检查是否是本轮投票（epoch）、是否来自LOOKING 状态的服务器。

3. **处理投票：**针对每一个投票，服务器都需要将别人的投票和自己的投票进行PK，PK 规则如下

   i. 优先比较epoch

   ii. 其次检查ZXID。ZXID 比较大的服务器优先作为Leader

   iii. 如果ZXID 相同，那么就比较myid。myid 较大的服务器作为Leader 服务器。

   对于Server1 而言，它的投票是(1, 0)，接收Server2 的投票为(2, 0)，首先会比较两者的ZXID，均为0，再比较myid，此Server2 的myid 最大，于是更新自己的投票为(2, 0)，然后重新投票，对于Server2 而言，其无须更新自己的投票，只是再次向集群中所有机器发出上一次投票信息即可。
   

4. **统计投票：**每次投票后，服务器都会统计投票信息，判断是否已经有过半机器接受到相同的投票信息，对于Server1、Server2 而言，都统计出集群中已经有两台机器接受了(2, 0)的投票信息，此时便认为已经选出了Leader。

5. **改变服务器状态：**一旦确定了Leader，每个服务器就会更新自己的状态，如果是Follower，那么就变更为FOLLOWING，如果是Leader，就变更为LEADING。

### 服务器运行期间的Leader 选举

当集群中的leader 服务器出现宕机或者不可用的情况时，那么整个集群将无法对外提供服务，而是进入新一轮的Leader 选举，服务器运行期间的Leader 选举和启动时期的Leader 选举基本过程是一致的。

1. **变更状态：**Leader 挂后，余下的非Observer 服务器都会将自己的服
   务器状态变更为LOOKING，然后开始进入Leader 选举过程。
2. **每个Server 会发出一个投票：**在运行期间，每个服务器上的ZXID 可能不同，此时假定Server1 的ZXID 为123，Server3 的ZXID 为122；在第一轮投票中，Server1 和Server3 都会投自己，产生投票(1, 123)，(3, 122)，然后各自将投票发送给集群中所有机器。接收来自各个服务器的投票。与启动时过程相同。
3. **处理投票：**与启动时过程相同，此时，Server1 将会成为Leader。
4. **统计投票：**与启动时过程相同。
5. **改变服务器的状态：**与启动时过程相同

## Watcher 机制

